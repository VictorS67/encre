import { similarity as mlDistanceSimilarity } from 'ml-distance';
import { maximalMarginalRelevance } from '../../../../utils/math.js';
import { getRecordId } from '../../../../utils/nanoid.js';

import { Context } from '../docs/index.js';
import { BaseVectorStore, type BaseVectorStoreField } from './base.js';

/**
 * Represents the fields for the MemoryVectorStore which include a list of vectors and a
 * similarity function definition, with optional filters.
 */
export interface MemoryVectorStoreField extends BaseVectorStoreField {
  /**
   * A list of all vectors currently stored in the memory. Each vector includes its content,
   * embedding, and metadata.
   */
  vectors: Vector[];

  /**
   * The function used to calculate the similarity between two vectors. This is typically a
   * cosine similarity function from a machine learning library.
   */
  similarity: typeof mlDistanceSimilarity.cosine;

  /**
   * Optional filters that can be applied during vector retrieval operations to limit the
   * results based on custom logic.
   */
  filter?: MemoryVectorStoreFilterType;
}

/**
 * Defines the parameters for the delete operation in a MemoryVectorStore. This allows
 * specifying vector IDs to delete or applying a filter to determine which vectors to delete.
 * @template T The type of the filter used in the delete operation.
 */
export interface MemoryDeleteParams<T> {
  /**
   * Optional list of vector IDs to be deleted. If specified, only vectors with these IDs
   * will be considered for deletion.
   */
  ids?: string[];

  /**
   * An optional filter used to determine which vectors should be deleted. The filter must be
   * compatible with the type of filtering logic implemented in the vector store.
   */
  filter?: T;
}

/**
 * Represents a vector within the MemoryVectorStore. Each vector has an identifier, content
 * text, a numerical embedding, and any associated metadata.
 */
export type Vector = {
  /**
   * A unique identifier for the vector.
   */
  id: string;

  /**
   * The content associated with the vector, typically a string of text from which the
   * embedding is derived.
   */
  content: string;

  /**
   * The numerical embedding of the content, represented as an array of numbers. Embeddings
   * are usually generated by a machine learning model to capture semantic meanings of the
   * content.
   */
  embedding: number[];

  /**
   * A dictionary containing metadata associated with the vector. This can include additional
   * information like tags, categories, or any other contextual data that supports the
   * application's use case.
   */
  metadata: Record<string, unknown>;
};

/**
 * Defines the filter type for the MemoryVectorStore. Filters can include a function to
 * determine inclusion based on context, and an option to include embeddings in the returned data.
 */
export type MemoryVectorStoreFilterType = {
  /**
   * An optional function that determines whether a given context meets certain criteria.
   * This function should be asynchronous and return a boolean indicating whether the context
   * passes the filter. This allows for dynamic and complex filtering logic based on the
   * context's properties.
   */
  filterFunc?: (context: Context) => Promise<boolean>;

  /**
   * Specifies whether embeddings should be included in the retrieval results. If set to true,
   * the embeddings associated with the vectors are included in the returned data, allowing
   * further operations or analyses that require access to the raw embeddings.
   */
  includeEmbeddings?: boolean;
};

/**
 * Provides an in-memory implementation of a vector store that supports operations such as adding,
 * deleting, and searching vectors based on similarity or relevance. This class is suitable for
 * lightweight applications or environments where persistence is not required.
 *
 * @example
 * ```typescript
 * // Create an instance of the MemoryVectorStore
 * const vectorStore = new MemoryVectorStore();
 *
 * // Example embeddings and contexts
 * const embeddings = [
 *   [0.1, 0.2, 0.3],
 *   [0.4, 0.5, 0.6],
 *   [0.7, 0.8, 0.9]
 * ];
 * const contexts = [
 *   new Context({ pageContent: "First context", metadata: { topic: "Science" }}),
 *   new Context({ pageContent: "Second context", metadata: { topic: "Technology" }}),
 *   new Context({ pageContent: "Third context", metadata: { topic: "Mathematics" }})
 * ];
 *
 * // Add vectors to the store
 * await vectorStore.addVectors(embeddings, contexts);
 *
 * // Perform a similarity search
 * const query = [0.1, 0.1, 0.1];
 * const topK = 2;
 * const searchResults = await vectorStore.similaritySearch(query, topK);
 *
 * // Log the search results
 * console.log("Search Results:", searchResults.map(r => ({ content: r[0].pageContent, score: r[1] })));
 * ```
 */
export class MemoryVectorStore
  extends BaseVectorStore
  implements MemoryVectorStoreField
{
  /**
   * Defines the filter type for the MemoryVectorStore. Filters can include a function to
   * determine inclusion based on context, and an option to include embeddings in the returned data.
   */
  declare FilterType: MemoryVectorStoreFilterType;

  _isSerializable = true;

  /**
   * A list of all vectors currently stored in the memory. Each vector includes its content,
   * embedding, and metadata.
   */
  vectors: Vector[];

  /**
   * The function used to calculate the similarity between two vectors. This is typically a
   * cosine similarity function from a machine learning library.
   */
  similarity: typeof mlDistanceSimilarity.cosine;

  /**
   * Optional filters that can be applied during vector retrieval operations to limit the
   * results based on custom logic.
   */
  filter?: this['FilterType'];

  _vectorstoreType(): string {
    return 'memory';
  }

  constructor(fields?: Partial<MemoryVectorStoreField>) {
    super(fields);

    this.vectors = fields?.vectors ?? [];
    this.similarity = fields?.similarity ?? mlDistanceSimilarity.cosine;
    this.filter = fields?.filter;
  }

  async addVectors(
    embeddings: number[][],
    context: Context[],
    options?: { ids?: string[] }
  ): Promise<void> {
    if (embeddings.length === 0) {
      return;
    }

    if (embeddings.length !== context.length) {
      throw new Error(
        'Memory addVectors: unmatched # of embeddings and # of contexts'
      );
    }

    let ids: string[] = options?.ids ?? [];
    if (ids.length > 0 && ids.length > embeddings.length) {
      console.warn(
        'Memory addVectors: # of ids is larger than # of embeddings. Now truncate last few ids'
      );

      ids = ids.slice(0, embeddings.length);
    } else if (ids.length > 0 && ids.length < embeddings.length) {
      console.warn(
        'Memory addVectors: # of ids is less than # of embeddings. Now pad last few ids with some random ids'
      );

      const paddingArray = Array.from(
        { length: embeddings.length - ids.length },
        () => getRecordId()
      );
      ids = ids.concat(paddingArray);
    } else if (ids.length === 0) {
      ids = Array.from({ length: embeddings.length }, () => getRecordId());
    }

    const newVectors: Vector[] = embeddings.map((embedding, index) => ({
      id: ids[index],
      content: context[index].pageContent,
      embedding,
      metadata: context[index].metadata,
    }));

    this.vectors = this.vectors.concat(newVectors);
  }

  async deleteVectors(
    params?: MemoryDeleteParams<this['FilterType']>
  ): Promise<void> {
    if (params?.ids || params?.filter) {
      let filteredVectors: Vector[] = this.vectors;

      if (params?.filter) {
        const _filter = params?.filter;

        const filterFunc = async (vector: Vector) => {
          if (!_filter.filterFunc) {
            return true;
          }

          const context = new Context({
            pageContent: vector.content,
            metadata: vector.metadata,
          });

          return _filter.filterFunc(context);
        };

        filteredVectors = filteredVectors.filter(filterFunc);
      }

      if (params?.ids) {
        const _ids: string[] = params?.ids ?? [];

        filteredVectors = filteredVectors.filter((v) => _ids.includes(v.id));
      }

      const vectorIdsToDelete: string[] = filteredVectors.map((v) => v.id);

      this.vectors = this.vectors.filter(
        (v) => !vectorIdsToDelete.includes(v.id)
      );
    } else {
      throw new Error(
        "Chroma deleteVectors: must provide either 'ids' or 'filter'"
      );
    }
  }

  async similaritySearch(
    query: number[],
    topK: number,
    filter?: this['FilterType']
  ): Promise<[Context, number][]> {
    const _filter = filter ?? this.filter;

    const filterFunc = async (vector: Vector) => {
      if (!_filter?.filterFunc) {
        return true;
      }

      const context = new Context({
        pageContent: vector.content,
        metadata: vector.metadata,
      });

      return _filter.filterFunc(context);
    };

    const filteredVectors = this.vectors.filter(filterFunc);

    const searches = filteredVectors
      .map((vector, index) => ({
        similarity: this.similarity(query, vector.embedding),
        index,
      }))
      .sort((a, b) => (a.similarity > b.similarity ? -1 : 0))
      .slice(0, topK);

    return searches.map((search) => {
      const context = new Context({
        pageContent: filteredVectors[search.index].content,
        metadata: filteredVectors[search.index].metadata,
      });

      if (_filter?.includeEmbeddings) {
        context.metadata.embedding = filteredVectors[search.index].embedding;
      }

      const score = search.similarity;

      return [context, score];
    });
  }

  async maxMarginalRelevanceSearch(
    query: number[],
    topK: number,
    lambda: number,
    filter?: this['FilterType'] | undefined
  ): Promise<[Context, number][]> {
    const _filter = filter ?? this.filter;
    const includeEmbeddingsFlag = _filter?.includeEmbeddings || false;

    const searches = await this.similaritySearch(query, topK, {
      ..._filter,
      includeEmbeddings: true,
    });

    const embeddings = searches.map(
      (s) => s[0].metadata.embedding
    ) as number[][];

    const [mmrIndexes, mmrSimilarities] = maximalMarginalRelevance(
      query,
      embeddings,
      lambda,
      topK
    );

    return mmrIndexes.map((index) => {
      const context = searches[index][0];
      const similarity = mmrSimilarities[index];

      if (!includeEmbeddingsFlag) {
        delete context.metadata.embedding;
      }

      return [context, similarity];
    });
  }
}
